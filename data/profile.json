{
  "profile": {
    "name": "Shilpa Kuppili",
    "title": "AI/ML Engineer",
    "organization": "5+ Years Experience | Harrison, NJ",
    "profileImage": "assets/PIC.jpg",
    "cvPath": "assets/Shilpa_Kuppili_Resume.pdf",
    "metrics": [
      "5+ Years Experience",
      "22% Accuracy Improvement",
      "40% Processing Reduction",
      "92% Classification Accuracy"
    ]
  },

  "bio": {
    "introduction": "<span class=\"highlight\">AI/ML Engineer with 5+ years of hands-on experience</span> designing, building, and deploying machine learning models and data-driven systems. Skilled in solving real-world problems using <span class=\"highlight\">supervised and unsupervised learning, natural language processing, and deep learning techniques</span>. Strong background in <span class=\"highlight\">Python, TensorFlow, and cloud platforms like AWS, GCP, and Azure</span>. Proven track record of delivering production-ready ML solutions that improve decision-making, automate workflows, and support business goals.",
    "background": "Expertise in <span class=\"highlight\">Machine Learning & Deep Learning</span> including supervised learning, unsupervised learning, neural networks, time series forecasting, anomaly detection, transfer learning, and ensemble methods. Advanced experience with <span class=\"highlight\">Generative AI & LLMs</span> including transformers, fine-tuning, RAG (Retrieval-Augmented Generation), LangChain, Autogen, and embedding models. Proficient in <span class=\"highlight\">Cloud & MLOps</span> using AWS (SageMaker, EC2, S3, Lambda), GCP (Vertex AI, BigQuery), Azure (Azure ML, Copilot Studio), Docker, Kubernetes, MLflow, and DVC.",
    "researchFocus": "Specialized in <span class=\"highlight\">production-grade ML systems</span> with demonstrated success in healthcare risk prediction, behavioral health AI, document understanding, and computer vision applications. Expert in <span class=\"highlight\">prompt engineering techniques</span> including few-shot prompting, chain-of-thought reasoning, and tool use integration. Proven ability to deploy models using <span class=\"highlight\">Flask, FastAPI, TensorFlow Serving</span>, achieving <span class=\"highlight\">22% improvement in early intervention accuracy</span>, <span class=\"highlight\">40% reduction in manual processing time</span>, and <span class=\"highlight\">92% document classification accuracy</span> across enterprise-scale applications."
  },

  "contact": {
    "email": "shilpakp333@gmail.com",
    "phone": "+1 (984) 318-4336",
    "location": "Harrison, NJ",
    "githubUsername": "shilpa99999",
    "linkedin": "https://www.linkedin.com/in/shilpa-kuppili-a80ba2126/",
    "github": null,
    "googleScholar": null,
    "twitter": null,
    "website": null,
    "trailhead": null
  },

  "navigation": [
    {"label": "About", "href": "#banner"},
    {"label": "Experience", "href": "#publications"},
    {"label": "Projects", "href": "#projects"},
    {"label": "Skills", "href": "#skills"},
    {"label": "Education", "href": "#education"},
    {"label": "Contact", "href": "mailto:shilpakp333@gmail.com"}
  ],

  "publications": [
    {
      "id": "humana",
      "title": "AI/ML Engineer",
      "authors": "Humana | USA",
      "venue": "Aug 2025 – Present",
      "description": "<div class='impact-metrics'><span class='metric'>22% Accuracy Improvement</span><span class='metric'>40% Processing Reduction</span><span class='metric'>Healthcare ML</span><span class='metric'>NLP Pipelines</span></div><br/><strong>Key Achievements:</strong><br/>• <strong>Engineered machine learning models</strong> using scikit-learn, XGBoost, and TensorFlow to identify high-risk individuals for chronic conditions, <span class='highlight'>resulting in a 22% improvement in early intervention accuracy</span> across Medicare Advantage plans<br/>• <strong>Built NLP pipelines</strong> using Hugging Face Transformers and spaCy to extract diagnoses, medications, and symptoms from unstructured physician notes, <span class='highlight'>enabling downstream analytics</span> that supported more personalized patient care strategies<br/>• <strong>Fine-tuned domain-specific large language models (LLMs)</strong> for automating clinical summary generation and insurance claims review workflows, <span class='highlight'>reducing manual processing time by 40%</span> and improving internal audit consistency<br/>• <strong>Implemented end-to-end MLOps pipelines</strong> integrating MLflow for experiment tracking, DVC for dataset versioning, and Jenkins for automated retraining, <span class='highlight'>ensuring reproducibility and compliance</span> with HIPAA data governance standards<br/>• <strong>Monitored production-grade models</strong> using FastAPI and TensorFlow Serving on AWS SageMaker, implementing scalable CI/CD pipelines via GitHub Actions and <span class='highlight'>enabling real-time support</span> for clinical decision-making tools",
      "image": "images/humana-logo.svg",
      "links": {
        "paper": null,
        "github": null,
        "status": null
      }
    },
    {
      "id": "thoughti",
      "title": "AI Full Stack Developer",
      "authors": "Thoughti | USA",
      "venue": "Feb 2025 – Aug 2025",
      "description": "<div class='impact-metrics'><span class='metric'>25% Dropout Reduction</span><span class='metric'>40% Relevance Improvement</span><span class='metric'>Azure AI</span><span class='metric'>Copilot Studio</span></div><br/><strong>Key Achievements:</strong><br/>• <strong>Developed AI-powered chatbot</strong> on Microsoft Azure using Copilot Studio and Bot Framework, delivering personalized behavioral health support and <span class='highlight'>reducing user dropout rates by 25%</span><br/>• <strong>Trained CLU and CQA models</strong> in Azure AI Language Studio to classify user intent across five behavioral change stages, <span class='highlight'>improving interaction relevance by 40%</span><br/>• <strong>Streamlined the AI model lifecycle</strong> and secured data workflows using Azure Foundry, <span class='highlight'>reducing deployment time by 30%</span><br/>• <strong>Designed reusable prompt templates</strong> and chaining logic to align chatbot dialogue with user behavioral stage, improving coherence and emotional relevance<br/>• <strong>Orchestrated dynamic multi-step conversation flows</strong> in Copilot Studio and integrated 3+ external APIs for personalized response generation<br/>• <strong>Constructed language understanding pipelines</strong> to detect substance use indicators and symptoms, <span class='highlight'>achieving 87% precision in early detection</span><br/>• <strong>Led the development of an automated proposal drafting tool</strong> using Azure Foundry, Microsoft Fabric, and Autogen, reducing proposal creation time significantly<br/>• <strong>Architected a five-phase agent framework</strong> using Autogen and RAG for automated document analysis, <span class='highlight'>improving accuracy and speed by 50%</span><br/>• <strong>Mitigated LLM hallucinations by 35%</strong> and inference costs by 40% using tiered deployment of GPT-4.1 and o4-mini with prompt optimization",
      "image": "images/thoughti-logo.png",
      "links": {
        "paper": null,
        "github": null,
        "status": null
      }
    },
    {
      "id": "techcomb",
      "title": "ML Intern",
      "authors": "TechComb | Texas",
      "venue": "Aug 2024 – Dec 2024",
      "description": "<div class='impact-metrics'><span class='metric'>YOLOv8 Integration</span><span class='metric'>25% Inference Speed</span><span class='metric'>Computer Vision</span><span class='metric'>LLM Integration</span></div><br/><strong>Key Achievements:</strong><br/>• <strong>Engineered and implemented an LLM integrated bird detection and classification system</strong> using YOLOv8 for real-time bird localization and EfficientNet B0 for precise species identification<br/>• <strong>Pioneered LLM integration</strong> such as GPT-2 to provide detailed species-specific deterrent strategies, enhancing the system's practical utility<br/>• <strong>Integrated Gradio and optimized the end-to-end pipeline</strong>, <span class='highlight'>reducing inference time by 25%</span> and creating an intuitive user interface for non-technical users<br/>• <strong>Implemented real-time object detection</strong> using state-of-the-art YOLO architecture, achieving high accuracy in bird species classification across diverse environmental conditions<br/>• <strong>Developed comprehensive evaluation metrics</strong> and validation procedures to ensure model performance met production requirements",
      "image": "images/techcomb-logo.png",
      "links": {
        "paper": null,
        "github": null,
        "status": null
      }
    },
    {
      "id": "zsanalytics",
      "title": "AI/ML Intern",
      "authors": "ZSAnalytics | New York",
      "venue": "May 2024 – Aug 2024",
      "description": "<div class='impact-metrics'><span class='metric'>Custom GPT Model</span><span class='metric'>Mistral LLM</span><span class='metric'>NLP Tasks</span><span class='metric'>Knowledge Extraction</span></div><br/><strong>Key Achievements:</strong><br/>• <strong>Built a Custom GPT Model</strong> and fine-tuned transformer-based language models on enterprise call transcript data to extract relevant knowledge and summarize the transcript<br/>• <strong>Implemented a Mistral LLM Chatbot</strong> for varied NLP tasks to generate coherent and contextually relevant information across multiple business use cases<br/>• <strong>Developed end-to-end NLP pipelines</strong> for automatic summarization, entity extraction, and sentiment analysis from unstructured conversational data<br/>• <strong>Optimized model performance</strong> through prompt engineering and fine-tuning strategies, improving response quality and business relevance<br/>• <strong>Collaborated with cross-functional teams</strong> to integrate LLM capabilities into existing analytics workflows and dashboards",
      "image": "images/zsanalytics-logo.png",
      "links": {
        "paper": null,
        "github": null,
        "status": null
      }
    },
    {
      "id": "motherson",
      "title": "Senior Software Engineer",
      "authors": "Motherson Technology Services Limited | Bangalore, India",
      "venue": "Jun 2022 – Aug 2023",
      "description": "<div class='impact-metrics'><span class='metric'>92% Accuracy</span><span class='metric'>CNN + LSTM</span><span class='metric'>Document AI</span><span class='metric'>Feature Selection</span></div><br/><strong>Key Achievements:</strong><br/>• <strong>Applied recursive feature selection techniques</strong> for document understanding using LLM-based prompts, enhancing model interpretability and performance<br/>• <strong>Developed an AI-powered document classification model</strong>, automating the categorization of records with <span class='highlight'>an accuracy of 92%</span> using a combination of CNN and LSTM architectures<br/>• <strong>Implemented end-to-end document processing pipeline</strong> including preprocessing, feature extraction, model training, and deployment to production systems<br/>• <strong>Optimized deep learning architectures</strong> through hyperparameter tuning and architecture search, achieving significant improvements in classification performance<br/>• <strong>Collaborated with enterprise teams</strong> to deploy models that automated manual document workflows, resulting in substantial time and cost savings",
      "image": "images/motherson-logo.png",
      "links": {
        "paper": null,
        "github": null,
        "status": null
      }
    },
    {
      "id": "tcs",
      "title": "Software Engineer",
      "authors": "Tata Consultancy Services | Bangalore, India",
      "venue": "Dec 2018 – Jun 2022",
      "description": "<div class='impact-metrics'><span class='metric'>15% Response Reduction</span><span class='metric'>30% Recommendation Boost</span><span class='metric'>ResNet50</span><span class='metric'>Conversational AI</span></div><br/><strong>Key Achievements:</strong><br/>• <strong>Created a conversational AI chatbot</strong> for financial advice, <span class='highlight'>reducing customer query response time by 15%</span> and improving customer satisfaction scores<br/>• <strong>Designed an image classification pipeline</strong> using pre-trained ResNet50 model to categorize fashion products into various styles, <span class='highlight'>increasing product recommendation accuracy by 30%</span><br/>• <strong>Implemented transfer learning techniques</strong> to adapt pre-trained models for domain-specific classification tasks with limited labeled data<br/>• <strong>Built and deployed RESTful APIs</strong> for serving ML models in production, ensuring scalability and reliability for high-traffic applications<br/>• <strong>Developed data preprocessing and augmentation pipelines</strong> to improve model robustness and generalization across diverse product categories<br/>• <strong>Collaborated with product and business teams</strong> to understand requirements and deliver ML solutions that directly supported revenue-generating features",
      "image": "images/tcs-logo.svg",
      "links": {
        "paper": null,
        "github": null,
        "status": null
      }
    }
  ],

  "skills": {
    "programmingLanguages": [
      "Python (Primary ML/AI Development Language)",
      "Java (Enterprise Applications and Backend Systems)",
      "C (System Programming and Performance-Critical Code)",
      "C++ (High-Performance Computing and Optimization)",
      "R (Statistical Computing and Data Analysis)",
      "SQL (Database Queries and Data Manipulation)",
      "TypeScript (Full-Stack Development and Type Safety)",
      "Bash/Shell Scripting (Automation and DevOps)"
    ],
    "mlDeepLearning": [
      "Supervised Learning (Classification, Regression)",
      "Unsupervised Learning (Clustering, Dimensionality Reduction)",
      "Neural Networks (Feedforward, Convolutional, Recurrent)",
      "Deep Learning (CNN, LSTM, Transformer Architectures)",
      "Time Series Forecasting (ARIMA, Prophet, LSTM)",
      "Anomaly Detection (Isolation Forest, Autoencoders)",
      "Transfer Learning (Pre-trained Model Fine-Tuning)",
      "Active Learning (Human-in-the-Loop Training)",
      "Semi-Supervised Learning (Pseudo-Labeling)",
      "Model Evaluation (Cross-Validation, Metrics)",
      "Feature Engineering (Selection, Extraction, Creation)",
      "Hyperparameter Tuning (Grid Search, Bayesian Optimization)",
      "Ensemble Methods (Bagging, Boosting, Stacking)"
    ],
    "genaiLLMs": [
      "Generative AI (Text, Image, and Multi-modal Generation)",
      "Large Language Models (GPT, Claude, Gemini, Mistral)",
      "Transformers (BERT, GPT, T5, RoBERTa)",
      "Fine-Tuning (LoRA, QLoRA, Full Fine-Tuning)",
      "Retrieval-Augmented Generation (RAG Pipelines)",
      "LangChain (LLM Application Framework)",
      "Autogen (Multi-Agent AI Systems)",
      "Tokenization (BPE, WordPiece, SentencePiece)",
      "Embedding Models (Sentence Transformers, OpenAI Embeddings)",
      "Context Optimization (Prompt Compression, Context Windows)",
      "Few-shot Prompting (In-Context Learning)",
      "Chain-of-Thought Reasoning (Step-by-Step Problem Solving)",
      "Instruction Tuning (Alignment and Task-Specific Training)",
      "Tool Use Integration (Function Calling, API Integration)",
      "OpenAI API (GPT-4, GPT-3.5, Embeddings)",
      "Hugging Face Transformers (Pre-trained Models Library)",
      "Claude (Anthropic AI Assistant)",
      "ChatGPT (Conversational AI Interface)",
      "Gemini (Google's Multimodal AI)",
      "Google NotebookLM (AI-Powered Research)",
      "Cursor (AI-Powered Code Editor)",
      "Copilot Studio (Microsoft Low-Code AI Development)"
    ],
    "mlFrameworks": [
      "PyTorch (Deep Learning Framework)",
      "TensorFlow (End-to-End ML Platform)",
      "Keras (High-Level Neural Networks API)",
      "Scikit-learn (Classical ML Algorithms)",
      "Statsmodels (Statistical Modeling)",
      "XGBoost (Gradient Boosting Framework)",
      "LightGBM (Light Gradient Boosting)",
      "NLTK (Natural Language Toolkit)",
      "SpaCy (Industrial-Strength NLP)",
      "OpenCV (Computer Vision Library)",
      "Dlib (Face Recognition and Detection)",
      "Matplotlib (Data Visualization)",
      "Seaborn (Statistical Data Visualization)",
      "Plotly (Interactive Visualizations)"
    ],
    "dataEngineering": [
      "NumPy (Numerical Computing)",
      "Pandas (Data Manipulation and Analysis)",
      "Dask (Parallel Computing for Larger-than-Memory Data)",
      "PySpark (Apache Spark Python API)",
      "Apache Spark (Large-Scale Data Processing)",
      "Polars (High-Performance DataFrame Library)",
      "Apache Airflow (Workflow Orchestration)",
      "Apache Kafka (Real-Time Data Streaming)",
      "DBT (Data Build Tool for Transformations)"
    ],
    "cloudMLOps": [
      "AWS SageMaker (End-to-End ML Platform)",
      "AWS EC2 (Elastic Compute Cloud)",
      "AWS S3 (Object Storage)",
      "AWS Lambda (Serverless Computing)",
      "GCP Vertex AI (Unified ML Platform)",
      "GCP BigQuery (Data Warehouse)",
      "Azure Machine Learning (ML Platform)",
      "Azure Copilot Studio (AI Development)",
      "Azure AI Language Studio (NLP Services)",
      "Docker (Containerization)",
      "Kubernetes (Container Orchestration)",
      "MLflow (ML Lifecycle Management)",
      "DVC (Data Version Control)",
      "Weights & Biases (Experiment Tracking)",
      "TensorBoard (Visualization for TensorFlow)",
      "Git (Version Control)",
      "GitHub Actions (CI/CD Automation)",
      "Jenkins (Continuous Integration)",
      "Argo Workflows (Kubernetes-Native Workflows)",
      "CircleCI (Continuous Integration Platform)"
    ],
    "modelDeployment": [
      "Flask (Lightweight Web Framework)",
      "FastAPI (Modern API Framework)",
      "gRPC (High-Performance RPC Framework)",
      "ONNX (Open Neural Network Exchange)",
      "TorchServe (PyTorch Model Serving)",
      "TensorFlow Serving (Production ML Model Serving)",
      "Streamlit (ML App Development)",
      "Gradio (ML Model UI)",
      "REST APIs (RESTful API Design)",
      "GraphQL (Query Language for APIs)",
      "API Rate Limiting (Traffic Management)",
      "Caching Strategies (Redis, Memcached)"
    ],
    "databasesStorage": [
      "PostgreSQL (Relational Database)",
      "MySQL (Open Source Relational Database)",
      "MongoDB (Document-Oriented NoSQL)",
      "Redis (In-Memory Data Store)",
      "DynamoDB (AWS NoSQL Database)",
      "Cassandra (Distributed NoSQL Database)",
      "Pinecone (Vector Database for Embeddings)",
      "FAISS (Facebook AI Similarity Search)",
      "ChromaDB (Vector Database)",
      "Weaviate (Vector Search Engine)",
      "HDFS (Hadoop Distributed File System)",
      "Snowflake (Cloud Data Warehouse)",
      "Google BigQuery (Serverless Data Warehouse)",
      "Amazon Redshift (Data Warehouse)"
    ],
    "visualization": [
      "Power BI (Microsoft Business Intelligence)",
      "Tableau (Interactive Data Visualization)",
      "Looker (Business Intelligence Platform)",
      "Matplotlib (Python Plotting Library)",
      "Seaborn (Statistical Data Visualization)",
      "Plotly (Interactive Graphing Library)",
      "Dash (Python Web App Framework)"
    ],
    "softSkills": [
      "Problem Solving and Analytical Thinking",
      "Cross-Functional Team Collaboration",
      "Technical Documentation and Communication",
      "Agile and Scrum Methodologies",
      "Project Planning and Execution",
      "Stakeholder Management and Presentation",
      "Code Review and Mentoring",
      "Research and Continuous Learning"
    ]
  },

  "projects": [
    {
      "id": "healthcare-ml-risk",
      "title": "Healthcare ML Risk Prediction System",
      "year": "2025",
      "category": "machine-learning",
      "shortDescription": "Machine learning models to identify high-risk individuals for chronic conditions, achieving 22% improvement in early intervention accuracy.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>22% Accuracy Boost</span><span class='metric'>Medicare Advantage</span><span class='metric'>XGBoost + TensorFlow</span><span class='metric'>Production-Ready</span></div><br/>Engineered comprehensive machine learning models using scikit-learn, XGBoost, and TensorFlow to identify high-risk individuals for chronic conditions across Medicare Advantage plans. Built end-to-end NLP pipelines using Hugging Face Transformers and spaCy to extract structured information (diagnoses, medications, symptoms) from unstructured physician notes. Fine-tuned domain-specific large language models for automating clinical summary generation and insurance claims review workflows. Implemented complete MLOps infrastructure integrating MLflow for experiment tracking, DVC for dataset versioning, and Jenkins for automated model retraining. Deployed production-grade models using FastAPI and TensorFlow Serving on AWS SageMaker with scalable CI/CD pipelines via GitHub Actions. Results: 22% improvement in early intervention accuracy, 40% reduction in manual processing time, full HIPAA compliance, and real-time support for clinical decision-making tools.",
      "media": {
        "type": "image",
        "src": "images/healthcare-ml-risk.svg",
        "poster": null
      },
      "techStack": [
        "scikit-learn",
        "XGBoost",
        "TensorFlow",
        "Hugging Face Transformers",
        "spaCy",
        "AWS SageMaker",
        "MLflow",
        "DVC",
        "FastAPI",
        "Jenkins",
        "GitHub Actions"
      ],
      "metrics": [
        {"value": "22%", "label": "Accuracy Improvement"},
        {"value": "40%", "label": "Processing Reduction"},
        {"value": "HIPAA", "label": "Compliant"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    },
    {
      "id": "behavioral-health-chatbot",
      "title": "Behavioral Health AI Chatbot",
      "year": "2025",
      "category": "genai",
      "shortDescription": "Azure-based AI chatbot delivering personalized behavioral health support, reducing user dropout rates by 25%.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>25% Dropout Reduction</span><span class='metric'>40% Relevance Boost</span><span class='metric'>87% Detection Precision</span><span class='metric'>Azure AI</span></div><br/>Developed comprehensive AI-powered chatbot on Microsoft Azure using Copilot Studio and Bot Framework to deliver personalized behavioral health support. Trained CLU (Conversational Language Understanding) and CQA (Custom Question Answering) models in Azure AI Language Studio to classify user intent across five behavioral change stages. Streamlined AI model lifecycle and secured data workflows using Azure Foundry. Designed reusable prompt templates and advanced chaining logic to align chatbot dialogue with user behavioral stage. Orchestrated dynamic multi-step conversation flows and integrated 3+ external APIs for personalized response generation. Constructed language understanding pipelines to detect substance use indicators and symptoms with 87% precision. Deployed models via Azure Foundry with secure API endpoints ensuring scalable 24/7 access for 10K+ monthly users. Results: 25% reduction in user dropout, 40% improvement in interaction relevance, 87% precision in early detection, and 30% faster deployment time.",
      "media": {
        "type": "image",
        "src": "images/behavioral-health-chatbot.svg",
        "poster": null
      },
      "techStack": [
        "Azure Copilot Studio",
        "Azure Bot Framework",
        "Azure AI Language Studio",
        "Azure Foundry",
        "CLU Models",
        "CQA Models",
        "Prompt Engineering",
        "API Integration",
        "Microsoft Fabric"
      ],
      "metrics": [
        {"value": "25%", "label": "Dropout Reduction"},
        {"value": "87%", "label": "Detection Precision"},
        {"value": "10K+", "label": "Monthly Users"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    },
    {
      "id": "automated-proposal-tool",
      "title": "Automated Proposal Generation Tool",
      "year": "2025",
      "category": "genai",
      "shortDescription": "Multi-agent AI system using Autogen and RAG for automated proposal drafting, improving accuracy and speed by 50%.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>50% Speed Boost</span><span class='metric'>35% Hallucination Reduction</span><span class='metric'>40% Cost Savings</span><span class='metric'>Multi-Agent AI</span></div><br/>Led development of automated proposal drafting tool using Azure Foundry, Microsoft Fabric, and Autogen for intelligent document generation. Architected five-phase agent framework using Autogen and RAG (Retrieval-Augmented Generation) for automated document analysis and synthesis. Implemented tiered deployment strategy using GPT-4.1 for complex reasoning and o4-mini for routine tasks, with advanced prompt optimization. Developed multi-agent research pipeline using dynamic context injection and advanced prompt engineering techniques. Built comprehensive RAG system integrating vector databases for relevant information retrieval and context-aware generation. Created feedback loops and quality assurance mechanisms to ensure output accuracy and relevance. Results: 50% improvement in accuracy and speed, 35% reduction in LLM hallucinations, 40% reduction in inference costs, 45% faster response time, and significant time savings in proposal creation workflows.",
      "media": {
        "type": "image",
        "src": "images/automated-proposal-tool.svg",
        "poster": null
      },
      "techStack": [
        "Autogen",
        "RAG (Retrieval-Augmented Generation)",
        "Azure Foundry",
        "Microsoft Fabric",
        "GPT-4.1",
        "Vector Databases",
        "Prompt Engineering",
        "Multi-Agent Systems"
      ],
      "metrics": [
        {"value": "50%", "label": "Speed Improvement"},
        {"value": "35%", "label": "Hallucination Reduction"},
        {"value": "40%", "label": "Cost Savings"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    },
    {
      "id": "bird-detection-system",
      "title": "Bird Detection & Classification System",
      "year": "2024",
      "category": "machine-learning",
      "shortDescription": "LLM-integrated bird detection system using YOLOv8 for localization and EfficientNet for species identification.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>YOLOv8</span><span class='metric'>EfficientNet B0</span><span class='metric'>25% Faster Inference</span><span class='metric'>LLM Integration</span></div><br/>Engineered and implemented comprehensive LLM-integrated bird detection and classification system for agricultural and ecological applications. Developed real-time bird localization pipeline using YOLOv8 (You Only Look Once) state-of-the-art object detection architecture. Implemented precise species identification using EfficientNet B0 transfer learning approach. Pioneered innovative LLM integration using GPT-2 to provide detailed species-specific deterrent strategies and contextual information. Integrated Gradio framework for intuitive user interface accessible to non-technical users. Optimized end-to-end pipeline through model quantization, inference optimization, and caching strategies, reducing inference time by 25%. Created comprehensive evaluation framework including precision, recall, F1-score, and real-world validation. Deployed production-ready system with REST API endpoints for integration with existing agricultural management systems.",
      "media": {
        "type": "image",
        "src": "images/bird-detection-system.svg",
        "poster": null
      },
      "techStack": [
        "YOLOv8",
        "EfficientNet B0",
        "GPT-2",
        "PyTorch",
        "Gradio",
        "OpenCV",
        "Transfer Learning",
        "REST APIs"
      ],
      "metrics": [
        {"value": "Real-time", "label": "Detection"},
        {"value": "25%", "label": "Faster Inference"},
        {"value": "Production", "label": "Ready"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    },
    {
      "id": "custom-gpt-transcripts",
      "title": "Custom GPT for Call Transcript Analysis",
      "year": "2024",
      "category": "genai",
      "shortDescription": "Fine-tuned transformer models on enterprise call data for knowledge extraction and intelligent summarization.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>Custom GPT</span><span class='metric'>Mistral LLM</span><span class='metric'>Knowledge Extraction</span><span class='metric'>Enterprise NLP</span></div><br/>Built custom GPT model and fine-tuned transformer-based language models on enterprise call transcript data for automated knowledge extraction and summarization. Implemented Mistral LLM chatbot for varied NLP tasks including summarization, entity extraction, sentiment analysis, and information retrieval. Developed end-to-end NLP pipelines for processing unstructured conversational data at scale. Optimized model performance through advanced prompt engineering, few-shot learning, and domain-specific fine-tuning strategies. Created evaluation framework measuring summary quality, factual accuracy, and business relevance. Integrated LLM capabilities into existing analytics workflows and business intelligence dashboards. Deployed scalable inference infrastructure supporting high-volume transcript processing. Implemented feedback mechanisms for continuous model improvement based on user interactions and business outcomes.",
      "media": {
        "type": "image",
        "src": "images/custom-gpt-transcripts.svg",
        "poster": null
      },
      "techStack": [
        "GPT (Custom Fine-Tuned)",
        "Mistral LLM",
        "Hugging Face Transformers",
        "Prompt Engineering",
        "NLP Pipelines",
        "Entity Extraction",
        "Sentiment Analysis"
      ],
      "metrics": [
        {"value": "Custom", "label": "GPT Model"},
        {"value": "Enterprise", "label": "Scale"},
        {"value": "Multi-task", "label": "NLP"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    },
    {
      "id": "document-classification",
      "title": "AI Document Classification System",
      "year": "2023",
      "category": "machine-learning",
      "shortDescription": "CNN+LSTM hybrid architecture for automated document categorization achieving 92% accuracy.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>92% Accuracy</span><span class='metric'>CNN + LSTM</span><span class='metric'>Document AI</span><span class='metric'>Production Deploy</span></div><br/>Developed comprehensive AI-powered document classification model automating categorization of enterprise records with 92% accuracy. Implemented hybrid deep learning architecture combining Convolutional Neural Networks (CNN) for feature extraction and Long Short-Term Memory (LSTM) networks for sequential pattern recognition. Applied recursive feature selection techniques for document understanding using LLM-based prompts to enhance model interpretability. Built end-to-end document processing pipeline including preprocessing, OCR integration, feature extraction, model training, and deployment. Optimized deep learning architectures through systematic hyperparameter tuning and neural architecture search. Created comprehensive evaluation framework with cross-validation, confusion matrices, and production monitoring. Deployed production system automating manual document workflows, achieving substantial time and cost savings. Integrated with enterprise document management systems via REST APIs.",
      "media": {
        "type": "image",
        "src": "images/document-classification.svg",
        "poster": null
      },
      "techStack": [
        "CNN (Convolutional Neural Networks)",
        "LSTM (Long Short-Term Memory)",
        "TensorFlow",
        "Keras",
        "OCR (Optical Character Recognition)",
        "Feature Engineering",
        "LLM Prompts",
        "REST APIs"
      ],
      "metrics": [
        {"value": "92%", "label": "Accuracy"},
        {"value": "Hybrid", "label": "CNN+LSTM"},
        {"value": "Production", "label": "Deployed"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    },
    {
      "id": "financial-chatbot",
      "title": "Financial Advice Conversational AI",
      "year": "2022",
      "category": "genai",
      "shortDescription": "Conversational AI chatbot for financial advice, reducing customer query response time by 15%.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>15% Response Reduction</span><span class='metric'>Conversational AI</span><span class='metric'>NLP</span><span class='metric'>Customer Support</span></div><br/>Created comprehensive conversational AI chatbot for automated financial advice and customer support. Implemented natural language understanding pipeline for intent classification, entity extraction, and dialogue management. Developed context-aware response generation system providing personalized financial guidance. Integrated with backend systems for real-time account information, transaction history, and financial product recommendations. Built robust error handling and fallback mechanisms ensuring graceful degradation and human handoff when needed. Optimized response quality through prompt engineering and fine-tuning on financial domain conversations. Deployed scalable infrastructure supporting high-volume customer interactions with sub-second response times. Implemented comprehensive analytics and monitoring dashboards tracking user satisfaction, conversation success rates, and business impact. Results: 15% reduction in customer query response time, improved customer satisfaction scores, and reduced support team workload.",
      "media": {
        "type": "image",
        "src": "images/financial-chatbot.svg",
        "poster": null
      },
      "techStack": [
        "Conversational AI",
        "NLP (Natural Language Processing)",
        "Intent Classification",
        "Dialogue Management",
        "Entity Extraction",
        "Customer Support AI"
      ],
      "metrics": [
        {"value": "15%", "label": "Response Reduction"},
        {"value": "24/7", "label": "Availability"},
        {"value": "High", "label": "Satisfaction"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    },
    {
      "id": "fashion-classifier",
      "title": "Fashion Product Image Classification",
      "year": "2021",
      "category": "machine-learning",
      "shortDescription": "ResNet50-based image classification pipeline for fashion products, increasing recommendation accuracy by 30%.",
      "detailedDescription": "<div class='project-metrics'><span class='metric'>30% Accuracy Boost</span><span class='metric'>ResNet50</span><span class='metric'>Transfer Learning</span><span class='metric'>Computer Vision</span></div><br/>Designed comprehensive image classification pipeline using pre-trained ResNet50 model to categorize fashion products into various style categories. Implemented transfer learning approach fine-tuning pre-trained ImageNet weights for fashion domain. Developed data preprocessing and augmentation pipeline including resizing, normalization, rotation, flipping, and color jittering to improve model robustness. Created multi-class classification system identifying product categories, styles, colors, and patterns. Optimized model architecture and hyperparameters achieving 30% improvement in product recommendation accuracy. Built and deployed RESTful APIs for serving ML models in production with load balancing and auto-scaling. Integrated with e-commerce platform's recommendation engine and search systems. Implemented comprehensive monitoring and A/B testing framework measuring business impact. Results: 30% increase in product recommendation accuracy, improved search relevance, higher customer engagement, and increased conversion rates.",
      "media": {
        "type": "image",
        "src": "images/fashion-classifier.svg",
        "poster": null
      },
      "techStack": [
        "ResNet50",
        "Transfer Learning",
        "PyTorch",
        "Computer Vision",
        "Data Augmentation",
        "REST APIs",
        "A/B Testing"
      ],
      "metrics": [
        {"value": "30%", "label": "Accuracy Increase"},
        {"value": "ResNet50", "label": "Architecture"},
        {"value": "Production", "label": "Scale"}
      ],
      "links": {
        "website": null,
        "github": null,
        "details": "#"
      },
      "isExpandable": true
    }
  ],

  "certifications": [],

  "education": [
    {
      "degree": "Master of Science in Artificial Intelligence",
      "institution": "Yeshiva University",
      "location": "New York, NY",
      "year": "Aug 2023 – Dec 2024",
      "logo": "images/yeshiva-university-logo.png"
    }
  ],

  "siteConfig": {
    "siteTitle": "Shilpa Kuppili - AI/ML Engineer",
    "favicon": null,
    "themeColors": {
      "primaryRed": "#2E86AB",
      "lightRed": "#3498DB",
      "darkRed": "#1B4F72",
      "textDark": "#2C3E50",
      "textLight": "#6c757d",
      "bgLight": "#f8f9fa",
      "white": "#ffffff"
    },
    "domain": null,
    "googleAnalytics": null
  }
}
